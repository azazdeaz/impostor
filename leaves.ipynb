{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089cdee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "def query_image(contents: types.ContentListUnionDict):\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash-image-preview\",\n",
    "        contents=contents,\n",
    "    )\n",
    "    assert response.candidates is not None and len(response.candidates) > 0\n",
    "\n",
    "    res_parts = response.candidates[0].content.parts\n",
    "    assert isinstance(res_parts, list)\n",
    "    img = None\n",
    "    for part in res_parts:\n",
    "        print(\"Got multiple parts in response:\")\n",
    "        if part.text is not None:\n",
    "            print(part.text)\n",
    "        elif part.inline_data is not None:\n",
    "            img = Image.open(BytesIO(part.inline_data.data))\n",
    "            display(img)  # Display inline in notebook\n",
    "\n",
    "    assert img is not None, \"No image found in response\"\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54498083",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\\n\".join([\n",
    "    \"Create a detailed photorealistic strawberry leaf texture.\",\n",
    "    \"No stems and the background should be blue (far from any color in the leaf) for easy removal.\",\n",
    "    \"It should be flat and have minimal shadows.(Like a texture map.)\",\n",
    "    \"Dont have highlights or shiny parts.\",\n",
    "    \"Only create the terminal/central/apical leaflet of the trifoliate leaf.\",\n",
    "])\n",
    "\n",
    "central_leaflet_color = query_image([prompt])\n",
    "display(central_leaflet_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882c5d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\\n\".join([\n",
    "    \"This is the texture of the terminal/central/apical leaflet of the trifoliate strawberry leaf.\",\n",
    "    \"Please create the bump map for this texture.\",\n",
    "    \"A bump map is a grayscale image that represents surface height variations.\",\n",
    "])\n",
    "\n",
    "central_leaflet_bump =  query_image([prompt, central_leaflet_color])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e06788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_alpha_mask(image, tolerance=50):\n",
    "    \"\"\"\n",
    "    Create a black and white alpha mask using the top-left pixel color as the clip color.\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image in RGB or RGBA mode\n",
    "        tolerance: How close colors need to be to the clip color (0-255)\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image: Black and white mask where white=opaque, black=transparent\n",
    "    \"\"\"\n",
    "    # Get the background color from top-left pixel\n",
    "    clip_color = image.getpixel((0, 0))\n",
    "    print(\"Background color:\", clip_color)\n",
    "    \n",
    "    # Convert to RGB if needed for consistent processing\n",
    "    if image.mode == 'RGBA':\n",
    "        image = image.convert('RGB')\n",
    "    \n",
    "    # Get image data as array\n",
    "    data = image.getdata()\n",
    "    mask_data = []\n",
    "    \n",
    "    for pixel in data:\n",
    "        r, g, b = pixel[:3]  # Get RGB values\n",
    "        cr, cg, cb = clip_color[:3]  # Handle both RGB and RGBA clip colors\n",
    "        \n",
    "        # Calculate color distance\n",
    "        distance = ((r - cr) ** 2 + (g - cg) ** 2 + (b - cb) ** 2) ** 0.5\n",
    "        \n",
    "        if distance <= tolerance:\n",
    "            # Background color = black (transparent)\n",
    "            mask_data.append(0)\n",
    "        else:\n",
    "            # Foreground = white (opaque)\n",
    "            mask_data.append(255)\n",
    "    \n",
    "    # Create new grayscale mask image\n",
    "    mask = Image.new('L', image.size)\n",
    "    mask.putdata(mask_data)\n",
    "    return mask\n",
    "\n",
    "# Create alpha mask using the new function\n",
    "alpha_mask = create_alpha_mask(central_leaflet_color, tolerance=50)\n",
    "display(alpha_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5f1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_box_from_mask(mask):\n",
    "    \"\"\"\n",
    "    Get the bounding box of non-black pixels from an alpha mask.\n",
    "    \n",
    "    Args:\n",
    "        mask: PIL Image in grayscale mode ('L') where white=content, black=background\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (left, top, right, bottom) bounding box or None if no content found\n",
    "    \"\"\"\n",
    "    # For grayscale masks, getbbox() finds non-zero pixels\n",
    "    bbox = mask.getbbox()\n",
    "    if bbox:\n",
    "        print(f\"Bounding box from mask: {bbox}\")\n",
    "        print(f\"Size: {bbox[2] - bbox[0]} x {bbox[3] - bbox[1]}\")\n",
    "    else:\n",
    "        print(\"No content found in mask\")\n",
    "    return bbox\n",
    "\n",
    "def crop_images_to_bbox(images, bbox):\n",
    "    \"\"\"\n",
    "    Crop a list of images to the same bounding box.\n",
    "    \n",
    "    Args:\n",
    "        images: List of PIL Images\n",
    "        bbox: tuple (left, top, right, bottom) bounding box\n",
    "    \n",
    "    Returns:\n",
    "        List of cropped PIL Images, all with the same size\n",
    "    \"\"\"\n",
    "    if not images or not bbox:\n",
    "        return images\n",
    "    \n",
    "    cropped_images = []\n",
    "    for img in images:\n",
    "        cropped = img.crop(bbox)\n",
    "        cropped_images.append(cropped)\n",
    "    \n",
    "    return cropped_images\n",
    "\n",
    "# Get bounding box from the alpha mask\n",
    "bbox = get_bounding_box_from_mask(alpha_mask)\n",
    "\n",
    "\n",
    "# Now crop all images to the same bounding box\n",
    "images_to_crop = [central_leaflet_color, central_leaflet_bump, alpha_mask]\n",
    "cropped_images = crop_images_to_bbox(images_to_crop, bbox)\n",
    "\n",
    "# Save and display the cropped images\n",
    "central_leaflet_color_cropped = cropped_images[0]\n",
    "central_leaflet_bump_cropped = cropped_images[1]\n",
    "central_leaflet_mask_cropped = cropped_images[2]\n",
    "\n",
    "display(central_leaflet_color_cropped)\n",
    "display(central_leaflet_bump_cropped)\n",
    "display(central_leaflet_mask_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe16420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bump_to_normal(bump_image, strength=1.0):\n",
    "    \"\"\"\n",
    "    Convert a grayscale bump map to a normal map.\n",
    "    \n",
    "    Args:\n",
    "        bump_image: PIL Image in grayscale or RGB (will use luminance)\n",
    "        strength: Multiplier for the normal strength (default 1.0)\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image: Normal map in RGB format\n",
    "    \"\"\"\n",
    "    # Convert to grayscale array if needed\n",
    "    if bump_image.mode == 'RGBA':\n",
    "        # Use RGB channels, ignore alpha\n",
    "        bump_array = np.array(bump_image.convert('RGB'))\n",
    "        bump_gray = np.dot(bump_array[...,:3], [0.299, 0.587, 0.114])\n",
    "    elif bump_image.mode == 'RGB':\n",
    "        bump_array = np.array(bump_image)\n",
    "        bump_gray = np.dot(bump_array, [0.299, 0.587, 0.114])\n",
    "    else:\n",
    "        bump_gray = np.array(bump_image.convert('L'))\n",
    "    \n",
    "    # Normalize to 0-1 range\n",
    "    bump_gray = bump_gray.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Calculate gradients (surface derivatives)\n",
    "    grad_x = np.zeros_like(bump_gray)\n",
    "    grad_y = np.zeros_like(bump_gray)\n",
    "    \n",
    "    # Calculate X gradient (horizontal)\n",
    "    grad_x[:, 1:] = bump_gray[:, 1:] - bump_gray[:, :-1]\n",
    "    grad_x[:, 0] = grad_x[:, 1]  # Duplicate edge\n",
    "    \n",
    "    # Calculate Y gradient (vertical) \n",
    "    grad_y[1:, :] = bump_gray[1:, :] - bump_gray[:-1, :]\n",
    "    grad_y[0, :] = grad_y[1, :]  # Duplicate edge\n",
    "    \n",
    "    # Apply strength multiplier\n",
    "    grad_x *= strength\n",
    "    grad_y *= strength\n",
    "    \n",
    "    # Create normal vectors\n",
    "    # Normal = (-dx, -dy, 1) normalized\n",
    "    normal_x = -grad_x\n",
    "    normal_y = -grad_y  \n",
    "    normal_z = np.ones_like(grad_x)\n",
    "    \n",
    "    # Normalize the normal vectors\n",
    "    length = np.sqrt(normal_x**2 + normal_y**2 + normal_z**2)\n",
    "    normal_x /= length\n",
    "    normal_y /= length  \n",
    "    normal_z /= length\n",
    "    \n",
    "    # Convert from [-1,1] to [0,255] range\n",
    "    # Normal map uses: R=X, G=Y, B=Z\n",
    "    normal_r = ((normal_x + 1.0) * 0.5 * 255).astype(np.uint8)\n",
    "    normal_g = ((normal_y + 1.0) * 0.5 * 255).astype(np.uint8)  \n",
    "    normal_b = ((normal_z + 1.0) * 0.5 * 255).astype(np.uint8)\n",
    "    \n",
    "    # Stack into RGB image\n",
    "    normal_rgb = np.stack([normal_r, normal_g, normal_b], axis=-1)\n",
    "    \n",
    "    # Convert back to PIL Image\n",
    "    normal_map = Image.fromarray(normal_rgb, 'RGB')\n",
    "    \n",
    "    return normal_map\n",
    "\n",
    "# Generate normal map from your bump map\n",
    "central_leaflet_normal_cropped = bump_to_normal(central_leaflet_bump_cropped, strength=2.0)\n",
    "display(central_leaflet_normal_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1685b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "central_leaflet_color_cropped.putalpha(central_leaflet_mask_cropped)\n",
    "\n",
    "images = {\n",
    "    \"central_leaflet_color_cropped\": central_leaflet_color_cropped,\n",
    "    \"central_leaflet_mask_cropped\": central_leaflet_mask_cropped,\n",
    "    \"central_leaflet_bump_cropped\": central_leaflet_bump_cropped,\n",
    "    \"central_leaflet_normal_cropped\": central_leaflet_normal_cropped,\n",
    "}\n",
    "\n",
    "for name, img in images.items():\n",
    "    img = img.transpose(method=Image.FLIP_TOP_BOTTOM)\n",
    "    # Resize to 1024x1024 for consistency\n",
    "    img = img.resize((1024, 1024), resample=Image.LANCZOS)\n",
    "    img.save(f\"{name}.png\")\n",
    "    display(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "impostor (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
