{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089cdee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "prompt = (\n",
    "    \"Create a detailed photorealistic strawberry leaf texture.\",\n",
    "    \"No stems and the background should be blue (far from any color in the leaf) for easy removal.\",\n",
    "    \"It should be flat and have minimal shadows.(Like a texture map.)\",\n",
    "    \"Dont have highlights or shiny parts.\",\n",
    "    \"Only create the terminal/central/apical leaflet of the trifoliate leaf.\",\n",
    "\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-image-preview\",\n",
    "    contents=[prompt],\n",
    ")\n",
    "\n",
    "for part in response.candidates[0].content.parts:\n",
    "    if part.text is not None:\n",
    "        print(part.text)\n",
    "    elif part.inline_data is not None:\n",
    "        central = Image.open(BytesIO(part.inline_data.data))\n",
    "        central.save(\"generated_image.png\")\n",
    "        display(central)  # Display inline in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882c5d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    \"This is the texture of the terminal/central/apical leaflet of the trifoliate strawberry leaf.\",\n",
    "    \"Please create the bump map for this texture.\",\n",
    "    \"A bump map is a grayscale image that represents surface height variations.\",\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-image-preview\",\n",
    "    contents=[prompt, central],\n",
    ")\n",
    "\n",
    "for part in response.candidates[0].content.parts:\n",
    "    if part.text is not None:\n",
    "        print(part.text)\n",
    "    elif part.inline_data is not None:\n",
    "        bump = Image.open(BytesIO(part.inline_data.data))\n",
    "        bump.save(\"generated_image.png\")\n",
    "        display(bump)  # Display inline in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e06788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the background color (first pixel)\n",
    "clip_color = central.getpixel((0, 0))\n",
    "print(\"Background color:\", clip_color)\n",
    "\n",
    "# Function to convert clip color to alpha\n",
    "def color_to_alpha(image, clip_color, tolerance=30):\n",
    "    \"\"\"\n",
    "    Convert a specific color to transparent alpha channel\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image in RGB or RGBA mode\n",
    "        clip_color: RGB tuple of color to make transparent\n",
    "        tolerance: How close colors need to be to clip_color (0-255)\n",
    "    \"\"\"\n",
    "    # Convert to RGBA if not already\n",
    "    if image.mode != 'RGBA':\n",
    "        image = image.convert('RGBA')\n",
    "    \n",
    "    # Get image data as array\n",
    "    data = image.getdata()\n",
    "    new_data = []\n",
    "    \n",
    "    for pixel in data:\n",
    "        r, g, b = pixel[:3]  # Get RGB values\n",
    "        cr, cg, cb = clip_color\n",
    "        \n",
    "        # Calculate color distance\n",
    "        distance = ((r - cr) ** 2 + (g - cg) ** 2 + (b - cb) ** 2) ** 0.5\n",
    "        \n",
    "        if distance <= tolerance:\n",
    "            # Make transparent\n",
    "            new_data.append((r, g, b, 0))\n",
    "        else:\n",
    "            # Keep original with full alpha\n",
    "            new_data.append((r, g, b, 255))\n",
    "    \n",
    "    # Create new image with alpha\n",
    "    result = Image.new('RGBA', image.size)\n",
    "    result.putdata(new_data)\n",
    "    return result\n",
    "\n",
    "# Apply color clipping\n",
    "central_clipped = color_to_alpha(central, clip_color, tolerance=50)\n",
    "central_clipped.save(\"central_clipped.png\")\n",
    "display(central_clipped)\n",
    "central_bump_clipped = color_to_alpha(bump, clip_color, tolerance=50)\n",
    "central_bump_clipped.save(\"central_bump_clipped.png\")\n",
    "display(central_bump_clipped)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5f1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_bounding_box_and_crop(images):\n",
    "    \"\"\"\n",
    "    Find the maximum bounding box that includes all non-transparent pixels\n",
    "    from multiple PIL images and crop all images to that bounding box.\n",
    "    \n",
    "    Args:\n",
    "        images: List of PIL Images (should have alpha channel for transparency)\n",
    "    \n",
    "    Returns:\n",
    "        List of cropped PIL Images, all with the same size\n",
    "    \"\"\"\n",
    "    if not images:\n",
    "        return []\n",
    "    \n",
    "    # Initialize bounding box coordinates\n",
    "    min_x, min_y = float('inf'), float('inf')\n",
    "    max_x, max_y = 0, 0\n",
    "    \n",
    "    # Find the maximum bounding box across all images\n",
    "    for img in images:\n",
    "        # Convert to RGBA if not already\n",
    "        if img.mode != 'RGBA':\n",
    "            img = img.convert('RGBA')\n",
    "        \n",
    "        # Get the bounding box of non-transparent pixels\n",
    "        bbox = img.getbbox()\n",
    "        \n",
    "        if bbox:  # If image has non-transparent pixels\n",
    "            left, top, right, bottom = bbox\n",
    "            min_x = min(min_x, left)\n",
    "            min_y = min(min_y, top)\n",
    "            max_x = max(max_x, right)\n",
    "            max_y = max(max_y, bottom)\n",
    "    \n",
    "    # If no non-transparent pixels found in any image\n",
    "    if min_x == float('inf'):\n",
    "        return images  # Return original images\n",
    "    \n",
    "    # Calculate the maximum bounding box\n",
    "    max_bbox = (int(min_x), int(min_y), int(max_x), int(max_y))\n",
    "    print(f\"Maximum bounding box: {max_bbox}\")\n",
    "    print(f\"Crop size: {max_x - min_x} x {max_y - min_y}\")\n",
    "    \n",
    "    # Crop all images to the maximum bounding box\n",
    "    cropped_images = []\n",
    "    for img in images:\n",
    "        # Convert to RGBA if not already\n",
    "        if img.mode != 'RGBA':\n",
    "            img = img.convert('RGBA')\n",
    "        \n",
    "        # Crop to the maximum bounding box\n",
    "        cropped = img.crop(max_bbox)\n",
    "        cropped_images.append(cropped)\n",
    "    \n",
    "    return cropped_images\n",
    "\n",
    "# Example usage with your images\n",
    "images_to_crop = [central_clipped, central_bump_clipped]\n",
    "cropped_images = get_max_bounding_box_and_crop(images_to_crop)\n",
    "\n",
    "# Save and display the cropped images\n",
    "if cropped_images:\n",
    "    central_cropped = cropped_images[0]\n",
    "    bump_cropped = cropped_images[1]\n",
    "    \n",
    "    central_cropped.save(\"central_cropped.png\")\n",
    "    bump_cropped.save(\"bump_cropped.png\")\n",
    "    \n",
    "    print(\"Central leaf cropped:\")\n",
    "    display(central_cropped)\n",
    "    \n",
    "    print(\"Bump map cropped:\")\n",
    "    display(bump_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe16420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bump_to_normal(bump_image, strength=1.0):\n",
    "    \"\"\"\n",
    "    Convert a grayscale bump map to a normal map.\n",
    "    \n",
    "    Args:\n",
    "        bump_image: PIL Image in grayscale or RGB (will use luminance)\n",
    "        strength: Multiplier for the normal strength (default 1.0)\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image: Normal map in RGB format\n",
    "    \"\"\"\n",
    "    # Convert to grayscale array if needed\n",
    "    if bump_image.mode == 'RGBA':\n",
    "        # Use RGB channels, ignore alpha\n",
    "        bump_array = np.array(bump_image.convert('RGB'))\n",
    "        bump_gray = np.dot(bump_array[...,:3], [0.299, 0.587, 0.114])\n",
    "    elif bump_image.mode == 'RGB':\n",
    "        bump_array = np.array(bump_image)\n",
    "        bump_gray = np.dot(bump_array, [0.299, 0.587, 0.114])\n",
    "    else:\n",
    "        bump_gray = np.array(bump_image.convert('L'))\n",
    "    \n",
    "    # Normalize to 0-1 range\n",
    "    bump_gray = bump_gray.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Calculate gradients (surface derivatives)\n",
    "    grad_x = np.zeros_like(bump_gray)\n",
    "    grad_y = np.zeros_like(bump_gray)\n",
    "    \n",
    "    # Calculate X gradient (horizontal)\n",
    "    grad_x[:, 1:] = bump_gray[:, 1:] - bump_gray[:, :-1]\n",
    "    grad_x[:, 0] = grad_x[:, 1]  # Duplicate edge\n",
    "    \n",
    "    # Calculate Y gradient (vertical) \n",
    "    grad_y[1:, :] = bump_gray[1:, :] - bump_gray[:-1, :]\n",
    "    grad_y[0, :] = grad_y[1, :]  # Duplicate edge\n",
    "    \n",
    "    # Apply strength multiplier\n",
    "    grad_x *= strength\n",
    "    grad_y *= strength\n",
    "    \n",
    "    # Create normal vectors\n",
    "    # Normal = (-dx, -dy, 1) normalized\n",
    "    normal_x = -grad_x\n",
    "    normal_y = -grad_y  \n",
    "    normal_z = np.ones_like(grad_x)\n",
    "    \n",
    "    # Normalize the normal vectors\n",
    "    length = np.sqrt(normal_x**2 + normal_y**2 + normal_z**2)\n",
    "    normal_x /= length\n",
    "    normal_y /= length  \n",
    "    normal_z /= length\n",
    "    \n",
    "    # Convert from [-1,1] to [0,255] range\n",
    "    # Normal map uses: R=X, G=Y, B=Z\n",
    "    normal_r = ((normal_x + 1.0) * 0.5 * 255).astype(np.uint8)\n",
    "    normal_g = ((normal_y + 1.0) * 0.5 * 255).astype(np.uint8)  \n",
    "    normal_b = ((normal_z + 1.0) * 0.5 * 255).astype(np.uint8)\n",
    "    \n",
    "    # Stack into RGB image\n",
    "    normal_rgb = np.stack([normal_r, normal_g, normal_b], axis=-1)\n",
    "    \n",
    "    # Convert back to PIL Image\n",
    "    normal_map = Image.fromarray(normal_rgb, 'RGB')\n",
    "    \n",
    "    return normal_map\n",
    "\n",
    "# Generate normal map from your bump map\n",
    "normal_map = bump_to_normal(bump_cropped, strength=2.0)\n",
    "normal_map.save(\"normal_map.png\")\n",
    "\n",
    "print(\"Normal map generated:\")\n",
    "display(normal_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "impostor (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
